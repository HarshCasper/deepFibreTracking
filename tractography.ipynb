{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import nrrd\n",
    "import nibabel as nb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "\n",
    "from dipy.tracking import eudx\n",
    "from dipy.tracking.local import LocalTracking, ThresholdTissueClassifier\n",
    "from dipy.tracking.utils import random_seeds_from_mask\n",
    "from dipy.reconst.dti import TensorModel, quantize_evecs\n",
    "from dipy.reconst.csdeconv import (ConstrainedSphericalDeconvModel,\n",
    "                                   auto_response)\n",
    "from dipy.reconst.shm import CsaOdfModel\n",
    "from dipy.data import default_sphere\n",
    "from dipy.direction import peaks_from_model, DeterministicMaximumDirectionGetter\n",
    "from dipy.data import fetch_stanford_hardi, read_stanford_hardi, get_sphere\n",
    "from dipy.segment.mask import median_otsu\n",
    "from dipy.viz import actor, window\n",
    "from dipy.io.image import save_nifti\n",
    "from dipy.io import read_bvals_bvecs\n",
    "from dipy.core import gradients\n",
    "from dipy.tracking.streamline import Streamlines, transform_streamlines\n",
    "from dipy.io import read_bvals_bvecs\n",
    "from dipy.core.gradients import gradient_table, gradient_table_from_bvals_bvecs\n",
    "from dipy.reconst.dti import fractional_anisotropy\n",
    "from dipy.tracking import utils\n",
    "\n",
    "import src.dwi_tools as dwi_tools\n",
    "import src.nn_helper as nn_helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pTrainData_fibrePrediction = 'train_prediction_grid_normalized_dti_cs1_wholebrain.h5'\n",
    "pTrainData_fibreTracking = 'train_tracking_grid_normalized_dti_cs1_wholebrain.h5'\n",
    "pTrainInput = 'train_input_normalized_dti_cs1_wholebrain_'\n",
    "noCrossings = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nico/Code/deepFibreTracking\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "crop multi-shell DWI to single shell data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bvals,bvecs,gtab,dwi,aff,t1,binarymask = dwi_tools.loadHCPData('100307')\n",
    "dwi_subset, gtab_subset, bvals_subset, bvecs_subset = dwi_tools.cropDatsetToBValue(3000, bvals, bvecs, dwi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average b0 image is required for data normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "b0_idx = bvals < 10 # 10/02/18 NH: changed to work with HCP data\n",
    "b0 = dwi[..., b0_idx].mean(axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dwi_singleShell = np.concatenate((dwi_subset, dwi[..., b0_idx]), axis=3)\n",
    "bvals_singleShell = np.concatenate((bvals_subset, bvals[..., b0_idx]), axis=0)\n",
    "bvecs_singleShell = np.concatenate((bvecs_subset, bvecs[b0_idx,]), axis=0)\n",
    "gtab_singleShell = gradient_table(bvals=bvals_singleShell, bvecs=bvecs_singleShell, b0_threshold = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tractography"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we'll generate streamlines using different approaches. This is gonna be the foundation for the evaluation of our method. We'll also employ simulated as well as curated data for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roi_idx = (slice(20, 50), slice(55, 85), slice(38, 39)) #  splenium of the corpus callosum\n",
    "from dipy.tracking.utils import random_seeds_from_mask, seeds_from_mask\n",
    "ccmask, options = nrrd.read('100307/100307-ccSegmentation.nrrd')\n",
    "ccseeds = seeds_from_mask(ccmask, affine=aff)\n",
    "wholebrainseeds = seeds_from_mask(binarymask, affine=aff)\n",
    "validationSeeds = ccseeds[45:48]\n",
    "rndseeds = random_seeds_from_mask(binarymask, seeds_count=4000, seed_count_per_voxel=False, affine=aff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage erroneous voxels: 0.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nico/Code/deepFibreTracking/src/dwi_tools.py:51: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  weights_normed = (weights / b0)\n",
      "/home/nico/Code/deepFibreTracking/src/dwi_tools.py:51: RuntimeWarning: invalid value encountered in true_divide\n",
      "  weights_normed = (weights / b0)\n"
     ]
    }
   ],
   "source": [
    "dwi_singleShell_norm = dwi_tools.normalize_dwi(dwi_singleShell, b0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(dwi_tools)\n",
    "import src.dwi_tools as dwi_tools\n",
    "data_sh = dwi_tools.get_spherical_harmonics_coefficients(bvals=bvals_singleShell,bvecs=bvecs_singleShell,sh_order=4, dwi=dwi_singleShell_norm, b0 = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.8900338118028197"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(data_sh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "f = nib.streamlines.load('100307_new/tracts.trk', lazy_load=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "f = nib.streamlines.load('/home/nico/tract.trk', lazy_load=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sl = f.streamlines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Tensor Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "raw dwi data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime 168.62876892089844s\n"
     ]
    }
   ],
   "source": [
    "import dipy.reconst.dti as dti\n",
    "start_time = time.time()\n",
    "dti_model = dti.TensorModel(gtab_singleShell)#, fit_method='WLS')\n",
    "dti_fit = dti_model.fit(dwi_singleShell, mask=binarymask)\n",
    "dti_fit_odf = dti_fit.odf(sphere = default_sphere)\n",
    "dg = DeterministicMaximumDirectionGetter\n",
    "dg = dg.from_pmf(dti_fit_odf, max_angle=30., sphere=default_sphere)\n",
    "runtime = time.time() - start_time\n",
    "print('Runtime ' + str(runtime) + 's')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spherical harmonics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime 77.87579464912415s\n"
     ]
    }
   ],
   "source": [
    "from dipy.data import default_sphere\n",
    "from dipy.direction import DeterministicMaximumDirectionGetter\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "csd_model = ConstrainedSphericalDeconvModel(gtab_singleShell, None, sh_order=4)\n",
    "csd_fit = csd_model.fit(dwi_singleShell_norm, mask=binarymask)\n",
    "\n",
    "\n",
    "dg = DeterministicMaximumDirectionGetter.from_shcoeff(csd_fit.shm_coeff,\n",
    "                                                             max_angle=30.,\n",
    "                                                             sphere=default_sphere)\n",
    "runtime = time.time() - start_time\n",
    "print('Runtime ' + str(runtime) + 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(145, 174, 145, 15)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csd_fit.shm_coeff.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.3568129650249658"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(csd_fit.shm_coeff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "track and visualize streamlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dipy.tracking.local import BinaryTissueClassifier\n",
    "\n",
    "#binary_classifier = BinaryTissueClassifier(binarymask == 1)\n",
    "classifier = ThresholdTissueClassifier(dti_fit.fa, .2) # used to be 0.01 10/16/18\n",
    "streamline_generator = LocalTracking(dg, classifier, ccseeds, aff, step_size=.1)\n",
    "streamlines = list(streamline_generator)\n",
    "streamlines_filtered = dwi_tools.filterStreamlinesByLength(streamlines, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nico/anaconda3/lib/python3.6/site-packages/vtk/util/numpy_support.py:137: FutureWarning: Conversion of the second argument of issubdtype from `complex` to `np.complexfloating` is deprecated. In future, it will be treated as `np.complex128 == np.dtype(complex).type`.\n",
      "  assert not numpy.issubdtype(z.dtype, complex), \\\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(dwi_tools)\n",
    "import src.dwi_tools as dwi_tools\n",
    "from dipy.tracking.streamline import transform_streamlines\n",
    "streamlines_imageCS = transform_streamlines(streamlines_filtered_,np.linalg.inv(aff)) # project streamlines from RAS into image (voxel) coordinate system\n",
    "dwi_tools.visStreamlines(streamlines_imageCS,t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/99054\n",
      "10000/99054\n",
      "20000/99054\n",
      "30000/99054\n",
      "40000/99054\n",
      "50000/99054\n",
      "60000/99054\n",
      "70000/99054\n",
      "80000/99054\n",
      "90000/99054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nico/anaconda3/lib/python3.6/site-packages/vtk/util/numpy_support.py:137: FutureWarning: Conversion of the second argument of issubdtype from `complex` to `np.complexfloating` is deprecated. In future, it will be treated as `np.complex128 == np.dtype(complex).type`.\n",
      "  assert not numpy.issubdtype(z.dtype, complex), \\\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(dwi_tools)\n",
    "import src.dwi_tools as dwi_tools\n",
    "\n",
    "sl_slicer = dwi_tools.loadVTKstreamlines('100307_new/out.vtk')\n",
    "dwi_tools.visStreamlines(sl_slicer,t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-ball Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csamodel = CsaOdfModel(gtab, 4)\n",
    "sphere = get_sphere('symmetric724')\n",
    "start_time = time.time()\n",
    "csapeaks = peaks_from_model(model=csamodel,\n",
    "                            data=dwi,\n",
    "                            sphere=sphere,\n",
    "                            relative_peak_threshold=.5,\n",
    "                            min_separation_angle=25,\n",
    "                            mask=binarymask,\n",
    "                            return_odf=False,\n",
    "                            parallel=True,\n",
    "                            normalize_peaks=False)\n",
    "\n",
    "GFA = csapeaks.gfa\n",
    "runtime = time.time() - start_time\n",
    "print('Runtime ' + str(runtime) + ' s / GFA.shape (%d, %d, %d)' % GFA.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = ThresholdTissueClassifier(dtipeaks.gfa, .25)\n",
    "streamlines_generator = LocalTracking(csapeaks, classifier, seeds, np.identity(4), step_size=.5)\n",
    "streamlines = Streamlines(streamlines_generator)\n",
    "streamlines_filtered = dwi_tools.filterStreamlinesByLength(streamlines, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dwi_tools.visStreamlines(streamlines_filtered_dg,t1)\n",
    "#dwi_tools.visStreamlines(streamlines_filtered,t1,vol_slice_idx=76)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constrained Spherical Deconvolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use in case of b = 2,500 – 3,000 s/mm² data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response, ratio = auto_response(gtab_singleShell, dwi_singleShell, roi_radius=10, fa_thr=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csd_model = ConstrainedSphericalDeconvModel(gtab_singleShell, response)\n",
    "sphere = get_sphere('symmetric724')\n",
    "start_time = time.time()\n",
    "csd_peaks = peaks_from_model(model=csd_model,\n",
    "                             data=dwi_singleShell,\n",
    "                             sphere=sphere,\n",
    "                             mask=binarymask,\n",
    "                             relative_peak_threshold=.5,\n",
    "                             min_separation_angle=25,\n",
    "                             parallel=True)\n",
    "GFA = csd_peaks.gfa\n",
    "runtime = time.time() - start_time\n",
    "print('Runtime ' + str(runtime) + ' s / GFA.shape (%d, %d, %d)' % GFA.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csd_fit = csd_model.fit(dwi_singleShell, mask=binarymask)\n",
    "\n",
    "from dipy.direction import DeterministicMaximumDirectionGetter\n",
    "\n",
    "detmax_dg = DeterministicMaximumDirectionGetter.from_shcoeff(csd_fit.shm_coeff,\n",
    "                                                             max_angle=30.,\n",
    "                                                             sphere=sphere)\n",
    "streamlines_generator = LocalTracking(detmax_dg, classifier, ccseeds, aff, step_size=.1)\n",
    "streamlines = Streamlines(streamlines_generator)\n",
    "streamlines_filtered_dg = dwi_tools.filterStreamlinesByLength(streamlines, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = ThresholdTissueClassifier(csd_peaks.gfa, .2)\n",
    "streamlines_generator = LocalTracking(csd_peaks, classifier, ccseeds, aff, step_size=.1)\n",
    "streamlines = Streamlines(streamlines_generator)\n",
    "streamlines_filtered = dwi_tools.filterStreamlinesByLength(streamlines, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store intermediate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(pTrainInput + \"_sl_filt.npy\",streamlines_imageCS)\n",
    "np.save(pTrainInput + \"_seeds.npy\",ccseeds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del streamlines_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "streamlines_imageCS = np.load(pTrainInput + \"_sl_filt.npy\")\n",
    "streamlines_filtered = transform_streamlines(streamlines_imageCS, aff) # project streamlines from image (voxel) into RAS coordinate system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage erroneous voxels: 0.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nico/Code/deepFibreTracking/src/dwi_tools.py:51: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  weights_normed = (weights / b0)\n",
      "/home/nico/Code/deepFibreTracking/src/dwi_tools.py:51: RuntimeWarning: invalid value encountered in true_divide\n",
      "  weights_normed = (weights / b0)\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(dwi_tools)\n",
    "import src.dwi_tools as dwi_tools\n",
    "dwi_B0normalized = dwi_tools.normalize_dwi(dwi_singleShell, b0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "noX = 1\n",
    "noY = 1\n",
    "noZ = 1\n",
    "coordinateScaling = 1\n",
    "sh_order = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage erroneous voxels: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nico/Code/deepFibreTracking/src/dwi_tools.py:51: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  weights_normed = (weights / b0)\n",
      "/home/nico/Code/deepFibreTracking/src/dwi_tools.py:51: RuntimeWarning: invalid value encountered in true_divide\n",
      "  weights_normed = (weights / b0)\n"
     ]
    }
   ],
   "source": [
    "## SPHERICAL HARMONICS\n",
    "data_sh, weights, b0 = dwi_tools.get_spherical_harmonics_coefficients(dwi_subset, b0=b0, bvals=bvals_subset, bvecs=bvecs_subset, sh_order = sh_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rawData = dwi_B0normalized\n",
    "rawData = data_sh\n",
    "#rawData = tensors\n",
    "#rawData = dtiPeakDirs\n",
    "\n",
    "start_time = time.time()\n",
    "train_DWI,train_prevDirection, train_LikelyFibreDirections, train_nextDirection = dwi_tools.generateTrainingData(streamlines_filtered, rawData, affine=aff, noX=noX,noY=noY,noZ=noZ,coordinateScaling=coordinateScaling,distToNeighbours=1, noCrossings = noCrossings)\n",
    "runtime = time.time() - start_time\n",
    "print('Runtime ' + str(runtime) + ' s ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(pTrainData_fibrePrediction,\"w\") as f:\n",
    "    f.create_dataset('train_DWI',data=train_DWI)\n",
    "    f.create_dataset('train_curPosition',data=train_prevDirection)   \n",
    "    f.create_dataset('train_LikelyFibreDirections',data=train_LikelyFibreDirections)   \n",
    "    f.create_dataset('train_NextFibreDirection',data=train_nextDirection)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noGPUs = 1\n",
    "batch_size = 2**8\n",
    "#batch_size -= batch_size % noGPUs # make batch size divisible by no. of GPUs\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "f = h5py.File(pTrainData_fibrePrediction, \"r\")\n",
    "train_DWI = np.array(f[\"train_DWI\"].value)\n",
    "train_prevDirection = np.array(f[\"train_curPosition\"].value)\n",
    "train_likelyDirections = np.array(f[\"train_LikelyFibreDirections\"].value)\n",
    "train_nextDirection = np.array(f[\"train_NextFibreDirection\"].value)\n",
    "f.close()\n",
    "#train_lastDirection = np.expand_dims(train_lastDirection, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_LikelyFibreDirections = (train_LikelyFibreDirections + 1) / 2\n",
    "#train_lastDirection = (train_lastDirection + 1) / 2\n",
    "#train_DWI = nn_helper.normalizeDWI(train_DWI)\n",
    "##train_lastDirection_unit = nn_helper.normalizeStreamlineOrientation(train_lastDirection)\n",
    "##train_NextFibreDirection_unit = nn_helper.normalizeStreamlineOrientation(train_NextFibreDirection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nextDirection_sph = dwi_tools.convAllToSphCoords(train_nextDirection)\n",
    "train_prevDirection_sph = dwi_tools.convAllToSphCoords(train_prevDirection)\n",
    "train_nextDirection_sph[:,1] = (train_nextDirection_sph[:,1] + np.pi) / (2 * np.pi)\n",
    "train_prevDirection_sph[:,1] = (train_prevDirection_sph[:,1] + np.pi) / (2 * np.pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP / Bidirectional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w/ DROPOUT and BN\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers import Activation\n",
    "import importlib\n",
    "importlib.reload(nn_helper)\n",
    "from keras.callbacks import TensorBoard\n",
    "mlp_simple = nn_helper.get_mlp_simpleTracker(activation_function = LeakyReLU(), features = 2048, inputShapeDWI=train_DWI.shape[1:5],depth = 5, noGPUs=noGPUs)\n",
    "mlp_simple.fit([train_DWI], [train_prevDirection_sph,train_nextDirection_sph], batch_size=batch_size, epochs=200, verbose=1,validation_split=0.2, callbacks=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_simple_newNormalisation.fit([train_DWI], [train_prevDirection_sph,train_nextDirection_sph], batch_size=batch_size, epochs=200, verbose=2,validation_split=0.2, callbacks=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data scaled to [0,1]\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers import Activation\n",
    "import importlib\n",
    "importlib.reload(nn_helper)\n",
    "from keras.callbacks import TensorBoard\n",
    "mlp_simple_newNormalisation = nn_helper.get_mlp_simpleTracker(activation_function = LeakyReLU(), features = 128, inputShapeDWI=train_DWI.shape[1:5],depth = 3, noGPUs=noGPUs)\n",
    "mlp_simple_newNormalisation.fit([train_DWI], [train_prevDirection_sph,train_nextDirection_sph], batch_size=batch_size, epochs=200, verbose=1,validation_split=0.2, callbacks=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "advanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w/ DROPOUT and BN\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers import Activation\n",
    "import importlib\n",
    "importlib.reload(nn_helper)\n",
    "from keras.callbacks import TensorBoard\n",
    "mlp_simple_newNormalisation = nn_helper.get_mlp_simpleTracker(activation_function = LeakyReLU(), features = 2048, inputShapeDWI=train_DWI.shape[1:5],depth = 3, noGPUs=noGPUs)\n",
    "mlp_simple_newNormalisation.fit([train_DWI], [train_prevDirection_sph,train_nextDirection_sph], batch_size=batch_size, epochs=200, verbose=1,validation_split=0.2, callbacks=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "\n",
    "import importlib\n",
    "importlib.reload(nn_helper)\n",
    "from keras.callbacks import TensorBoard\n",
    "mlp_adv = nn_helper.get_mlp_advancedTracker(activation_function = Activation('tanh'), features = 512, inputShapeDWI=(noX, noY, noZ, 270),depth = 3, noGPUs=noGPUs, inputShapeStreamline=(3,1))\n",
    "#mlp_adv.summary()\n",
    "mlp_adv.fit([train_DWI,train_prevDirection], [train_NextFibreDirection], batch_size=batch_size, epochs=100, verbose=1,validation_split=0.2, callbacks=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UNET / Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def relu_advanced(x):\n",
    "    return K.relu(x, max_value=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "# see https://openreview.net/pdf?id=Hkuq2EkPf\n",
    "def swish(x, c = 0.1):\n",
    "    return x * K.sigmoid(tf.constant(c, dtype=tf.float32) * x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "max normalized DWI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Activation\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "import importlib\n",
    "import src.nn_helper as nn_helper\n",
    "importlib.reload(nn_helper)\n",
    "#unet_tracker = nn_helper.get_3Dunet_simpleTracker(activation_function = LeakyReLU(), inputShapeDWI=train_DWI.shape[1:5], depth = 3, noGPUs=2)\n",
    "unet_tracker.fit([train_DWI], [train_prevDirection_sph,train_nextDirection_sph], batch_size=batch_size, epochs=20, verbose=1,validation_split=0.2, callbacks=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Activation\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "import importlib\n",
    "import src.nn_helper as nn_helper\n",
    "importlib.reload(nn_helper)\n",
    "#unet_tracker = nn_helper.get_3Dunet_simpleTracker(activation_function = LeakyReLU(), inputShapeDWI=train_DWI.shape[1:5], depth = 3, noGPUs=2)\n",
    "unet_tracker.fit([train_DWI], [train_prevDirection_sph,train_nextDirection_sph], batch_size=batch_size, epochs=20, verbose=1,validation_split=0.2, callbacks=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 1\n",
    "praw,eraw = unet_tracker.predict([train_DWI[idx:idx+1,]])\n",
    "p = (2 * np.pi) * p - np.pi\n",
    "e = (2 * np.pi) * e - np.pi\n",
    "print(str(  np.mean(    (praw-train_prevDirection_sph[idx:idx+1,])**2            )))\n",
    "print(str(  np.mean(    (eraw-train_nextDirection_sph[idx:idx+1,])**2            )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_tracker.evaluate([train_DWI[idx:idx+1,]], [train_prevDirection_sph[idx:idx+1,],train_nextDirection_sph[idx:idx+1,]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y,z = dwi_tools.spheToEuclidean(1,p[0,0],p[0,1])\n",
    "print(str([x,y,z]))\n",
    "print(str(train_prevDirection[idx,]))\n",
    "xv,yv,zv = dwi_tools.spheToEuclidean(1,(2*np.pi)*train_prevDirection_sph[idx,0]+np.pi,(2*np.pi)*train_prevDirection_sph[idx,1]+np.pi)\n",
    "print(str([xv,yv,zv]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(np.sum((praw - train_prevDirection_sph[idx,])**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_tracker.save('trackingNetwork_unet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# duenner Klassifikations-Layer\n",
    "import src.nn_helper as nn_helper\n",
    "importlib.reload(nn_helper)\n",
    "unet_tracker = nn_helper.get_3Dunet_simpleTracker(activation_function = Activation(swish), inputShapeDWI=train_DWI.shape[1:5], depth = 3, noGPUs=noGPUs)\n",
    "unet_tracker.fit([train_DWI], [train_prevDirection,train_nextDirection], batch_size=batch_size, epochs=10, verbose=1,validation_split=0.2, callbacks=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### learnable activation layer\n",
    "from keras.engine.base_layer import Layer\n",
    "class LearnableSwishActivation(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(LearnableSwishActivation, self).__init__(**kwargs)\n",
    "        self.__name__ = 'SWISH'\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.output_dim = input_shape[1] \n",
    "        self.W = self.add_weight(shape=(1,), # Create a trainable weight variable for this layer.\n",
    "                                 initializer='one', trainable=True, name=\"swish_c\")\n",
    "        super(LearnableSwishActivation, self).build(input_shape)  # Be sure to call this somewhere!\n",
    "    def call(self, x, mask=None):\n",
    "        return x * K.sigmoid(self.W * x)\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return (input_shape[0], self.output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "x = tf.linspace(-5.,5.,10).eval(session=K.get_session())\n",
    "y = swish(tf.linspace(-5.,5.,10),c=-0.1).eval(session=K.get_session())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x,y);plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# duenner Klassifikations-Layer, mit Dropout und BN\n",
    "import src.nn_helper as nn_helper\n",
    "importlib.reload(nn_helper)\n",
    "unet_tracker = nn_helper.get_3Dunet_simpleTracker(activation_function = Activation(swish), inputShapeDWI=train_DWI.shape[1:5], depth = 3, noGPUs=noGPUs)\n",
    "unet_tracker.fit([train_DWI], [train_prevDirection,train_nextDirection], batch_size=batch_size, epochs=200, verbose=1,validation_split=0.2, callbacks=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import keras\n",
    "import src.nn_helper as nn_helper\n",
    "importlib.reload(nn_helper)\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger, ReduceLROnPlateau, EarlyStopping\n",
    "pModel = \"tractography_model_{epoch:02d}-{val_loss:.6f}.h5\"\n",
    "#unet_tracker_2 = nn_helper.get_3Dunet_simpleTracker(activation_function = keras.layers.core.Activation('relu'), inputShapeDWI=(noX, noY, noZ, 270),depth = 3, noGPUs=noGPUs)\n",
    "unet_tracker_2 = nn_helper.get_3Dunet_simpleTracker(activation_function = LeakyReLU(), inputShapeDWI=(noX, noY, noZ, 270),depth = 3, noGPUs=noGPUs)\n",
    "csv_logger = CSVLogger(\"tractography_log.csv\")\n",
    "checkpoint = ModelCheckpoint(pModel, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list=[checkpoint, csv_logger]\n",
    "unet_tracker_2.fit([train_DWI], [train_NextFibreDirection], batch_size=batch_size, epochs=100, verbose=1, validation_split=0.2, callbacks=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEBUG TRACKING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noX = 16\n",
    "noY = 16\n",
    "noZ = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dipy.align.vector_fields as vfu\n",
    "import tensorflow as tf\n",
    "validationSeeds = ccseeds[0:1]\n",
    "x_ = coordinateScaling * np.linspace(-8., 8., noX)\n",
    "y_ = coordinateScaling * np.linspace(-8., 8., noY)\n",
    "z_ = coordinateScaling * np.linspace(-8., 8., noZ)    \n",
    "z_ = 1\n",
    "noZ = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noSeeds = len(validationSeeds)\n",
    "noIterations = 1000\n",
    "dw = 270"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streamlinePositions = np.zeros([noSeeds,noIterations+1,3])\n",
    "streamlinePositions[:,0,] = validationSeeds[0:noSeeds]\n",
    "streamlinePositions[:,1,] = validationSeeds[0:noSeeds]\n",
    "x = np.zeros([noSeeds,noX,noY,noZ,dw])\n",
    "iter = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streamlinePositions[0,iter,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=dwi_B0normalized\n",
    "#model=msd_simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(0,noSeeds):\n",
    "    coordVecs = np.vstack(np.meshgrid(x_,y_,z_, indexing='ij')).reshape(3,-1).T + streamlinePositions[j,iter,]\n",
    "    for i in range(0,dw):\n",
    "        x[j,:,:,:,i] = np.reshape(vfu.interpolate_scalar_3d(data[:,:,:,i],coordVecs)[0], [noX,noY,noZ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import map_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values_tmp = map_coordinates(data[:,:,:,10], coordVecs.T, order = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = np.reshape(values_tmp, [noX,noY,noZ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordVecs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordVecs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordVecs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streamlinePositions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure('Showing the datasets')\n",
    "plt.subplot(1, 3, 1).set_axis_off()\n",
    "plt.imshow(data[62:78, 60:76, 62, 10].T, cmap='gray', origin='lower')\n",
    "plt.subplot(1, 3, 2).set_axis_off()\n",
    "plt.imshow(x[0,:,:,0,10].T, cmap='gray', origin='lower')\n",
    "plt.subplot(1, 3, 3).set_axis_off()\n",
    "plt.imshow(data[62:78, 60:76, 62, 10].T - x[0,:,:,0,10].T, cmap='gray', origin='lower')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(data[62:78, 60:76, 62, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(x[0,:,:,0,10].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(data[62:78, 60:76, 62, 10].T - x[0,:,:,0,10].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    y2 = msd_simple.predict([x])\n",
    "    #y3 = unet_tracker_2.predict([train_DWI[0:1,]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_NextFibreDirection_unit[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import keras.backend as K\n",
    "keras.losses.mse(y,np.float32(train_NextFibreDirection_unit[0])).eval(session=K.get_session())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import (array, dot, arccos, clip) \n",
    "from numpy.linalg import norm \n",
    "\n",
    "u = y\n",
    "v = train_NextFibreDirection[0]\n",
    "c = dot(u,v)/norm(u)/norm(v)\n",
    "angle = arccos(clip(c, -1, 1)) \n",
    "angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = nn_helper.denormalizeStreamlineOrientation(u)\n",
    "v = nn_helper.denormalizeStreamlineOrientation(v)\n",
    "c = dot(u,v)/norm(u)/norm(v)\n",
    "angle = arccos(clip(c, -1, 1)) \n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy = y / np.sqrt(np.sum(y ** 2))\n",
    "yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vv = v / np.sqrt(np.sum(v ** 2))\n",
    "vv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = ThresholdTissueClassifier(dtipeaks.gfa, .25)\n",
    "streamlines_generator = LocalTracking(dtipeaks, classifier, validationSeeds, np.identity(4), step_size=.1)\n",
    "#streamlines_generator = LocalTracking(dtipeaks, classifier, ccseeds, aff, step_size=.1)\n",
    "streamlines_val = Streamlines(streamlines_generator)\n",
    "streamlines_filtered_val = dwi_tools.filterStreamlinesByLength(streamlines, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP/Bidirectional Tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validationSeeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.tracking as tracking\n",
    "importlib.reload(tracking)\n",
    "start_time = time.time()\n",
    "streamlines_mlp_simple,vNorms = tracking.applySimpleTrackerNetwork(useSph=True,seeds=validationSeeds,data=dwi_B0normalized, model=mlp_simple_newNormalisation, nnOutputToUse = 0, noX=noX, noY=noY, noZ=noZ, dw = 270, stepWidth = 0.1, coordinateScaling = coordinateScaling)\n",
    "runtime = time.time() - start_time\n",
    "print('Runtime ' + str(runtime) + ' s ')\n",
    "import src.tracking as tracking\n",
    "importlib.reload(tracking)\n",
    "start_time = time.time()\n",
    "streamlines_mlp_simple_2,vNorms2 = tracking.applySimpleTrackerNetwork(useSph=True,seeds=validationSeeds,data=dwi_B0normalized, model=mlp_simple_newNormalisation, nnOutputToUse = 1, noX=noX, noY=noY, noZ=noZ, dw = 270, stepWidth = 0.1, coordinateScaling = coordinateScaling)\n",
    "runtime = time.time() - start_time\n",
    "print('Runtime ' + str(runtime) + ' s ')\n",
    "streamlines_mlp_simple_f = np.fliplr(streamlines_mlp_simple)\n",
    "streamlines_joined = np.concatenate([streamlines_mlp_simple_f,streamlines_mlp_simple_2],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streamlines_mlp_simple = streamlines_mlp_simple[0]\n",
    "streamlines_mlp_simple_2 = streamlines_mlp_simple_2[0]\n",
    "streamlines_mlp_simple_f = np.fliplr(streamlines_mlp_simple)\n",
    "streamlines_joined = np.concatenate([streamlines_mlp_simple_f,streamlines_mlp_simple_2],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.dwi_tools as dwi_tools\n",
    "importlib.reload(dwi_tools)\n",
    "dwi_tools.visTwoSetsOfStreamlines(streamlines_val,streamlines_joined,t1[:,:,:], vol_slice_idx = 75, vol_slice_idx2 = 55)\n",
    "#dwi_tools.visStreamlines(streamlines_val,t1, vol_slice_idx = 73)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('streamlines_validation.npy', streamlines_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streamlines_val = np.load('streamlines_validation.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dwi_tools.visStreamlines(streamlines_msd_adv,t1, vol_slice_idx = 73)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UNET/Bidirectional tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_tracker.save('trackingNetwork.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.tracking as tracking\n",
    "importlib.reload(tracking)\n",
    "start_time = time.time()\n",
    "streamlines_mlp_simple,vNorms = tracking.applySimpleTrackerNetwork(useSph=True,seeds=validationSeeds,data=dwi_B0normalized, model=unet_tracker, nnOutputToUse = 0, noX=noX, noY=noY, noZ=noZ, dw = 270, stepWidth = 0.1, coordinateScaling = coordinateScaling)\n",
    "runtime = time.time() - start_time\n",
    "print('Runtime ' + str(runtime) + ' s ')\n",
    "import src.tracking as tracking\n",
    "importlib.reload(tracking)\n",
    "start_time = time.time()\n",
    "streamlines_mlp_simple_2,vNorms2 = tracking.applySimpleTrackerNetwork(useSph=True,seeds=validationSeeds,data=dwi_B0normalized, model=unet_tracker, nnOutputToUse = 1, noX=noX, noY=noY, noZ=noZ, dw = 270, stepWidth = 0.1, coordinateScaling = coordinateScaling)\n",
    "runtime = time.time() - start_time\n",
    "print('Runtime ' + str(runtime) + ' s ')\n",
    "streamlines_mlp_simple_f = np.fliplr(streamlines_mlp_simple)\n",
    "streamlines_joined = np.concatenate([streamlines_mlp_simple_f,streamlines_mlp_simple_2],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.dwi_tools as dwi_tools\n",
    "importlib.reload(dwi_tools)\n",
    "dwi_tools.visTwoSetsOfStreamlines(streamlines_val,streamlines_joined,t1[:,:,:], vol_slice_idx = 75, vol_slice_idx2 = 55)\n",
    "#dwi_tools.visStreamlines(streamlines_val,t1, vol_slice_idx = 73)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(vNorms.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(vNorms2.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
