{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import nrrd\n",
    "import nibabel as nb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "\n",
    "from dipy.tracking.local import LocalTracking, ThresholdTissueClassifier\n",
    "from dipy.tracking.utils import random_seeds_from_mask\n",
    "from dipy.reconst.dti import TensorModel\n",
    "from dipy.reconst.csdeconv import (ConstrainedSphericalDeconvModel,\n",
    "                                   auto_response)\n",
    "from dipy.reconst.shm import CsaOdfModel\n",
    "from dipy.data import default_sphere\n",
    "from dipy.direction import peaks_from_model\n",
    "from dipy.data import fetch_stanford_hardi, read_stanford_hardi, get_sphere\n",
    "from dipy.segment.mask import median_otsu\n",
    "from dipy.viz import actor, window\n",
    "from dipy.io.image import save_nifti\n",
    "from dipy.io import read_bvals_bvecs\n",
    "from dipy.core import gradients\n",
    "from dipy.tracking.streamline import Streamlines\n",
    "from dipy.io import read_bvals_bvecs\n",
    "from dipy.core.gradients import gradient_table, gradient_table_from_bvals_bvecs\n",
    "from dipy.reconst.dti import fractional_anisotropy\n",
    "\n",
    "from dipy.tracking import utils\n",
    "\n",
    "import src.dwi_tools as dwi_tools\n",
    "import src.nn_helper as nn_helper\n",
    "import src.tracking as tracking\n",
    "\n",
    "from dipy.tracking.streamline import values_from_volume\n",
    "import dipy.align.vector_fields as vfu\n",
    "from dipy.core.sphere import Sphere\n",
    "from dipy.core import subdivide_octahedron \n",
    "from scipy.spatial import KDTree\n",
    "from dipy.core import subdivide_octahedron \n",
    "\n",
    "from dipy.tracking.local import LocalTracking\n",
    "from dipy.viz import window, actor\n",
    "from dipy.viz.colormap import line_colors\n",
    "from dipy.tracking.streamline import Streamlines, transform_streamlines\n",
    "from dipy.tracking import metrics\n",
    "from dipy.tracking.utils import random_seeds_from_mask, seeds_from_mask\n",
    "\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "import tensorflow as tf\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "from keras.models import load_model\n",
    "from keras.layers import Activation\n",
    "\n",
    "import importlib\n",
    "importlib.reload(tracking)\n",
    "importlib.reload(nn_helper)\n",
    "import src.tracking as tracking\n",
    "import tensorflow as tf\n",
    "from src.nn_helper import swish, squared_cosine_proximity_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load seed mask and prepare our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model with  (dx 1, dy 1, dz 1) and 15 channels\n",
      "Importing HCP data\n",
      "Spherical Harmonics (ours)\n",
      "Percentage erroneous voxels: 3.87\n"
     ]
    }
   ],
   "source": [
    "stepWidth = 0.6\n",
    "coordinateScaling = 1\n",
    "useDTIPeakDirection = True\n",
    "useSphericalHarmonics = False\n",
    "print('Loaded model with  (dx %d, dy %d, dz %d) and %d channels' % (noX, noY, noZ, noC))\n",
    "\n",
    "if(noC == 3):\n",
    "    useDTIPeakDirection = True\n",
    "    \n",
    "if(noC == 15):\n",
    "    useSphericalHarmonics = True\n",
    "    sh_order = 4\n",
    "elif(noC == 45):\n",
    "    useSphericalHarmonics = True\n",
    "    sh_order = 8\n",
    "\n",
    "# load DWI data\n",
    "print('Importing HCP data')\n",
    "bvals,bvecs,gtab,dwi,aff,t1,binarymask = dwi_tools.loadHCPData('data/100307')\n",
    "dwi_subset, gtab_subset, bvals_subset, bvecs_subset = dwi_tools.cropDatsetToBValue(3000, bvals, bvecs, dwi)\n",
    "b0_idx = bvals < 10\n",
    "b0 = dwi[..., b0_idx].mean(axis=3)\n",
    "\n",
    "dwi_singleShell = np.concatenate((dwi_subset, dwi[..., b0_idx]), axis=3)\n",
    "bvals_singleShell = np.concatenate((bvals_subset, bvals[..., b0_idx]), axis=0)\n",
    "bvecs_singleShell = np.concatenate((bvecs_subset, bvecs[b0_idx,]), axis=0)\n",
    "gtab_singleShell = gradient_table(bvals=bvals_singleShell, bvecs=bvecs_singleShell, b0_threshold = 10)\n",
    "\n",
    "tracking_data = dwi_singleShell\n",
    "\n",
    "### exract the averaged b0.\n",
    "\n",
    "if(useSphericalHarmonics):\n",
    "    print('Spherical Harmonics (ours)')\n",
    "    dwi_singleShell_norm = dwi_tools.normalize_dwi(dwi_singleShell, b0)\n",
    "    \n",
    "    #CSD/DIPY APPROACH\n",
    "    print('Spherical Harmonics (dipy)')\n",
    "    #csd_model = ConstrainedSphericalDeconvModel(gtab_singleShell, None, sh_order=sh_order)\n",
    "    #csd_fit = csd_model.fit(dwi_singleShell_norm, mask=binarymask)\n",
    "    #tracking_data = csd_fit.shm_coeff\n",
    "    \n",
    "    dwi_singleShell_norm = dwi_tools.normalize_dwi(dwi_singleShell, b0)\n",
    "    tracking_data = dwi_tools.get_spherical_harmonics_coefficients(bvals=bvals_singleShell,bvecs=bvecs_singleShell,sh_order=4, dwi=dwi_singleShell_norm, b0 = 0)\n",
    "\n",
    "# DTI PEAK DIRECTION INPUT\n",
    "if(useDTIPeakDirection):\n",
    "    print('DTI Peak Direction/odf estimation')\n",
    "    import dipy.reconst.dti as dti\n",
    "    start_time = time.time()\n",
    "    dti_model = dti.TensorModel(gtab_singleShell, fit_method='LS')\n",
    "    dti_fit = dti_model.fit(dwi_singleShell)\n",
    "    dti_fit_odf = dti_fit.odf(sphere = default_sphere)\n",
    "    runtime = time.time() - start_time\n",
    "    print('Runtime ' + str(runtime) + 's')\n",
    "    \n",
    "# corpus callosum seed mask\n",
    "ccmask, options = nrrd.read('data/100307/100307-ccSegmentation.nrrd')\n",
    "ccseeds = seeds_from_mask(ccmask, affine=aff)\n",
    "# whole brain seeds\n",
    "wholebrainseeds = seeds_from_mask(binarymask, affine=aff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('huhu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi (DWI,PrevTension) -> Tension tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pModel = 'results/102218_train_OLDsh4_step10_wholeBrain_b1k_1x1/models/mlp_doubleIn_single_sqCos2_wb_dx_1_dy_1_dz_1_dd_15_ReLU_feat_512_depth_3_output_3_lr_0.0001_dropout_1_bn_1_pt_0_4172--0.974801.h5'\n",
    "pModel = 'results/train_prediction_grid_normalized_dti_cs1_wholebrain/models/mlp_doubleIn_single_sqCos2_wb_dx_1_dy_1_dz_1_dd_15_ReLU_feat_512_depth_3_output_3_lr_0.0001_dropout_1_bn_0_pt_0_4846--0.977051.h5'\n",
    "pResult = pModel.replace('.h5','').replace('/models/','_') + '-prediction'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker = load_model(pModel , custom_objects={'tf':tf, 'swish':Activation(swish), 'squared_cosine_proximity': squared_cosine_proximity, 'squared_cosine_proximity_2': squared_cosine_proximity_2})\n",
    "noSamples, noX, noY, noZ, noC = tracker.get_input_shape_at(0)[0]\n",
    "#tracker.summary()\n",
    "useBitracker = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dipy.tracking.streamline import set_number_of_points, Streamlines\n",
    "sl_est_2 = set_number_of_points(Streamlines(streamlines_joined_imageCS), nb_points = 20)\n",
    "sl_val_2 = set_number_of_points(Streamlines(streamlines_val.tolist()), nb_points = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dipy.segment.metric import SumPointwiseEuclideanMetric\n",
    "from dipy.segment import quickbundles\n",
    "\n",
    "dist = quickbundles.bundles_distances_mdf(sl_est_2, sl_val_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_minIdx = np.argmin(dist, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single DWI -> TENSION tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pModel = 'results/102218_train_OLDsh4_step10_wholeBrain_b1k_1x1/models/mlp_single_mse_wb_dx_1_dy_1_dz_1_dd_15_ReLU_feat_512_depth_3_output_3_lr_0.0001_dropout_1_bn_1_pt_0_950-0.489318.h5'\n",
    "\n",
    "#pModel = 'results/102218_train_OLDsh4_step10_wholeBrain_b1k_1x1/models/mlp_single_cos_wb_dx_1_dy_1_dz_1_dd_15_ReLU_feat_512_depth_3_output_3_lr_0.0001_dropout_1_bn_1_pt_0_1173--0.263056.h5'\n",
    "\n",
    "pModel = 'results/102218_train_OLDsh4_step10_wholeBrain_b1k_1x1/models/mlp_single_sqCos2_wb_dx_1_dy_1_dz_1_dd_15_ReLU_feat_512_depth_3_output_3_lr_0.0001_dropout_1_bn_1_pt_0_7217--0.968468.h5'\n",
    "\n",
    "pModel = 'results/train_OLDsh4_step0.1_wholeBrain_b1k_1x1x1_step10/models/mlp_single_sqCos2_wb_dx_1_dy_1_dz_1_dd_15_ReLU_feat_512_depth_3_output_3_lr_0.0001_dropout_1_bn_1_pt_0_6691--0.990052.h5'\n",
    "\n",
    "#pModel = 'results/train_prediction_grid_normalized_dti_cs1_wholebrain/models/mlp_single_sqCos2_wb_dx_1_dy_1_dz_1_dd_15_ReLU_feat_512_depth_3_output_3_lr_0.0001_dropout_1_bn_0_pt_0_9960--0.858613.h5'\n",
    "\n",
    "pResult = pModel.replace('.h5','').replace('/models/','_') + '-prediction'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker = load_model(pModel , custom_objects={'tf':tf, 'swish':Activation(swish), 'squared_cosine_proximity': squared_cosine_proximity_2, 'squared_cosine_proximity_2': squared_cosine_proximity_2})\n",
    "noSamples, noX, noY, noZ, noC = tracker.get_input_shape_at(0)\n",
    "#tracker.summary()\n",
    "useBitracker = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Tracking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do tracking (wholebrainseeds, ccseeds)\n",
    "importlib.reload(tracking)\n",
    "import src.tracking as tracking\n",
    "start_time = time.time()\n",
    "streamlines_mlp_simple, vec_norm = tracking.start(bitracker=useBitracker,inverseDirection=False,seeds=ccseeds,data=data_sh, affine=aff, model=tracker, noX=noX, noY=noY, noZ=noZ, dw = noC, stepWidth = 0.6, coordinateScaling = coordinateScaling)\n",
    "runtime = time.time() - start_time\n",
    "print('Runtime ' + str(runtime) + ' s ')\n",
    "\n",
    "start_time = time.time()\n",
    "streamlines_mlp_simple_2, vec_norm_2 = tracking.start(bitracker=useBitracker,inverseDirection=True,seeds=ccseeds,data=data_sh, affine=aff, model=tracker, noX=noX, noY=noY, noZ=noZ, dw = noC, stepWidth = 0.6, coordinateScaling = coordinateScaling)\n",
    "runtime = time.time() - start_time\n",
    "print('Runtime ' + str(runtime) + ' s ')\n",
    "\n",
    "# visualize results\n",
    "streamlines_mlp_simple_f = np.fliplr(streamlines_mlp_simple)\n",
    "streamlines_joined = np.concatenate([streamlines_mlp_simple_f,streamlines_mlp_simple_2],axis=1)    \n",
    "\n",
    "streamlines_joined_imageCS = transform_streamlines(streamlines_joined, np.linalg.inv(aff))\n",
    "                                                   \n",
    "np.save(pResult + '-ijk.vtk', streamlines_joined_imageCS)\n",
    "np.save(pResult + '-ras.vtk', streamlines_joined)\n",
    "dwi_tools.saveVTKstreamlines(streamlines_joined,pResult + '.vtk')\n",
    "                                                   \n",
    "dwi_tools.visStreamlines(streamlines_joined_imageCS,t1, vol_slice_idx = 75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(tracking)\n",
    "import src.tracking as tracking\n",
    "\n",
    "start_time = time.time()\n",
    "streamlines_mlp_simple_sc,vNorms = tracking.startWithStopping(mask=binarymask,fa=dti_fit.fa, bitracker=False, inverseDirection=False, seeds=ccseeds,data=data_sh, affine=aff, model=tracker, noX=noX, noY=noY, noZ=noZ, dw = noC, stepWidth = 0.6, coordinateScaling = coordinateScaling)\n",
    "runtime = time.time() - start_time\n",
    "print('Runtime ' + str(runtime) + ' s ')\n",
    "\n",
    "start_time = time.time()\n",
    "streamlines_mlp_simple_sc_2,vNorms2 = tracking.startWithStopping(mask=binarymask,fa=dti_fit.fa, bitracker=False, inverseDirection=True, seeds=ccseeds,data=data_sh, affine=aff, model=tracker, noX=noX, noY=noY, noZ=noZ, dw = noC, stepWidth = 0.6, coordinateScaling = coordinateScaling)\n",
    "runtime = time.time() - start_time\n",
    "print('Runtime ' + str(runtime) + ' s ')\n",
    "\n",
    "# join left and right streamlines\n",
    "streamlines_joined_sc = tracking.joinTwoAlignedStreamlineLists(streamlines_mlp_simple_sc,streamlines_mlp_simple_sc_2)\n",
    "\n",
    "streamlines_joined_sc_imageCS_bn = transform_streamlines(streamlines_joined_sc, np.linalg.inv(aff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize streamlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dwi_tools.visStreamlines(transform_streamlines(streamlines_joined, np.linalg.inv(aff)),t1, vol_slice_idx = 75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dwi_tools.visTwoSetsOfStreamlines(streamlines_joined_sc_imageCS,streamlines_joined_sc_imageCS_bn, t1, vol_slice_idx = 75)\n",
    "# first set of streamlines is red\n",
    "# second set of streamline is green"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
