{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import nrrd\n",
    "import nibabel as nb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "\n",
    "from dipy.tracking.local import LocalTracking, ThresholdTissueClassifier\n",
    "from dipy.tracking.utils import random_seeds_from_mask\n",
    "from dipy.reconst.dti import TensorModel\n",
    "from dipy.reconst.csdeconv import (ConstrainedSphericalDeconvModel,\n",
    "                                   auto_response)\n",
    "from dipy.reconst.shm import CsaOdfModel\n",
    "from dipy.data import default_sphere\n",
    "from dipy.direction import peaks_from_model\n",
    "from dipy.data import fetch_stanford_hardi, read_stanford_hardi, get_sphere\n",
    "from dipy.segment.mask import median_otsu\n",
    "from dipy.viz import actor, window\n",
    "from dipy.io.image import save_nifti\n",
    "from dipy.io import read_bvals_bvecs\n",
    "from dipy.core import gradients\n",
    "from dipy.tracking.streamline import Streamlines\n",
    "from dipy.io import read_bvals_bvecs\n",
    "from dipy.core.gradients import gradient_table, gradient_table_from_bvals_bvecs\n",
    "from dipy.reconst.dti import fractional_anisotropy\n",
    "\n",
    "from dipy.tracking import utils\n",
    "\n",
    "import src.dwi_tools as dwi_tools\n",
    "import src.nn_helper as nn_helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pTrainData_fibrePrediction = 'train_prediction_grid_normalized_dti.h5'\n",
    "pTrainData_fibreTracking = 'train_tracking_grid_normalized_dti.h5'\n",
    "pTrainInput = 'train_input_normalized_dti_'\n",
    "noCrossings = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load bvec/bval and compute gradient table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bvals, bvecs = read_bvals_bvecs('100307/bvals', '100307/bvecs')\n",
    "gtab = gradient_table(bvals=bvals, bvecs=bvecs,b0_threshold=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = nb.load('100307/data.nii.gz')\n",
    "dwi = img.get_data()\n",
    "aff = img.affine\n",
    "img = nb.load('100307/T1w_acpc_dc_restore_1.25.nii.gz')\n",
    "t1 = img.get_data()\n",
    "binarymask, options = nrrd.read('100307/nodif_brain_mask.nrrd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "aff = np.eye(4,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "visualize DWI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axial_middle = dwi.shape[2] // 2\n",
    "plt.figure('Showing the datasets')\n",
    "plt.subplot(1, 2, 1).set_axis_off()\n",
    "plt.imshow(dwi[:, :, axial_middle, 0].T, cmap='gray', origin='lower')\n",
    "plt.subplot(1, 2, 2).set_axis_off()\n",
    "plt.imshow(dwi[:, :, axial_middle, 10].T, cmap='gray', origin='lower')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tractography"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we'll generate streamlines using different approaches. This is gonna be the foundation for the evaluation of our method. We'll also employ simulated as well as curated data for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roi_idx = (slice(20, 50), slice(55, 85), slice(38, 39)) #  splenium of the corpus callosum\n",
    "from dipy.tracking.utils import random_seeds_from_mask, seeds_from_mask\n",
    "ccmask = np.zeros(binarymask.shape)\n",
    "ccmask[20:50,55:85,38:39] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccseeds = seeds_from_mask(ccmask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccmask, options = nrrd.read('100307/100307-ccSegmentation.nrrd')\n",
    "ccseeds = seeds_from_mask(ccmask, affine=aff)\n",
    "ccseedsNoAffine = seeds_from_mask(ccmask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slicer/UKF Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diffusion Tensor Imaging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compute fractional anisotropy and select seeds_count seeds per voxel with FA > 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dipy.reconst.dti as dti\n",
    "dti_wls = dti.TensorModel(gtab)\n",
    "fit_wls = dti_wls.fit(dwi)\n",
    "FA = fit_wls.fa\n",
    "seeds = random_seeds_from_mask(FA > 0.5, seeds_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sphere = get_sphere('symmetric724')\n",
    "start_time = time.time()\n",
    "dtipeaks = peaks_from_model(model=dti_wls,\n",
    "                            data=dwi,\n",
    "                            sphere=sphere,\n",
    "                            relative_peak_threshold=.5,\n",
    "                            min_separation_angle=25,\n",
    "                            mask=binarymask,\n",
    "                            return_odf=False,\n",
    "                            parallel=True,\n",
    "                            normalize_peaks=False,\n",
    "                            nbr_processes=48\n",
    "                           )\n",
    "runtime = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GFA = dtipeaks.gfa\n",
    "print('Runtime ' + str(runtime) + 's / GFA.shape (%d, %d, %d)' % GFA.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = ThresholdTissueClassifier(dtipeaks.gfa, .25)\n",
    "streamlines_generator = LocalTracking(dtipeaks, classifier, ccseeds, np.identity(4), step_size=.1)\n",
    "#streamlines_generator = LocalTracking(dtipeaks, classifier, ccseeds, aff, step_size=.1)\n",
    "streamlines = Streamlines(streamlines_generator)\n",
    "streamlines_filtered = dwi_tools.filterStreamlinesByLength(streamlines, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dwi_tools.visStreamlines(streamlines_filtered,t1,vol_slice_idx=40)\n",
    "#dwi_tools.visStreamlines(streamlines_filtered,t1,vol_slice_idx=76)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-ball Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csamodel = CsaOdfModel(gtab, 4)\n",
    "sphere = get_sphere('symmetric724')\n",
    "start_time = time.time()\n",
    "csapeaks = peaks_from_model(model=csamodel,\n",
    "                            data=dwi,\n",
    "                            sphere=sphere,\n",
    "                            relative_peak_threshold=.5,\n",
    "                            min_separation_angle=25,\n",
    "                            mask=binarymask,\n",
    "                            return_odf=False,\n",
    "                            parallel=True,\n",
    "                            normalize_peaks=False)\n",
    "\n",
    "GFA = csapeaks.gfa\n",
    "runtime = time.time() - start_time\n",
    "print('Runtime ' + str(runtime) + ' s / GFA.shape (%d, %d, %d)' % GFA.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = ThresholdTissueClassifier(dtipeaks.gfa, .25)\n",
    "streamlines_generator = LocalTracking(csapeaks, classifier, seeds, np.identity(4), step_size=.5)\n",
    "streamlines = Streamlines(streamlines_generator)\n",
    "streamlines_filtered = dwi_tools.filterStreamlinesByLength(streamlines, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dwi_tools.visStreamlines(streamlines,t1)\n",
    "#dwi_tools.visStreamlines(streamlines_filtered,t1,vol_slice_idx=76)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constrained Spherical Deconvolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use in case of b = 2,500 – 3,000 s/mm² data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response, ratio = auto_response(gtab, dwi, roi_radius=10, fa_thr=0.5)\n",
    "print(response)\n",
    "print(ratio)\n",
    "csd_model = ConstrainedSphericalDeconvModel(gtab, response)\n",
    "sphere = get_sphere('symmetric724')\n",
    "start_time = time.time()\n",
    "csd_peaks = peaks_from_model(model=csd_model,\n",
    "                             data=dwi,\n",
    "                             sphere=sphere,\n",
    "                             mask=binarymask,\n",
    "                             relative_peak_threshold=.5,\n",
    "                             min_separation_angle=25,\n",
    "                             parallel=True)\n",
    "GFA = csd_peaks.gfa\n",
    "runtime = time.time() - start_time\n",
    "print('Runtime ' + str(runtime) + ' s / GFA.shape (%d, %d, %d)' % GFA.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = ThresholdTissueClassifier(csd_peaks.gfa, .25)\n",
    "streamlines_generator = LocalTracking(csd_peaks, classifier, ccseeds, np.identity(4), step_size=.5)\n",
    "streamlines = Streamlines(streamlines_generator)\n",
    "streamlines_filtered = dwi_tools.filterStreamlinesByLength(streamlines, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streamlines_filtered.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dwi_tools.visStreamlines(streamlines_filtered,t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store intermediate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(pTrainInput + \"_sl_filt.npy\",streamlines_filtered)\n",
    "np.save(pTrainInput + \"_sl.npy\",streamlines)\n",
    "np.save(pTrainInput + \"_seeds.npy\",seeds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prepare training data for fibre direction network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dwi_B0normalized = dwi / np.max(dwi[:, :, :, gtab.b0s_mask]) # normalize data.. typically averaging would be used however that would yield dwi values way above 1 (6.5)\n",
    "dwi_B0normalized = dwi_B0normalized[:, :, :, ~gtab.b0s_mask]  # remove B0 scans from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "noX = 8\n",
    "noY = 8\n",
    "noZ = 8\n",
    "coordinateScaling = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(dwi_tools)\n",
    "streamlines_filtered = np.asarray(np.load(pTrainInput + \"_sl_filt.npy\"))\n",
    "#np.random.shuffle(streamlines_filtered)\n",
    "import src.dwi_tools as dwi_tools\n",
    "import src.nn_helper as nn_helper\n",
    "start_time = time.time()\n",
    "train_DWI,train_curPosition, train_LikelyFibreDirections, train_NextFibreDirection = dwi_tools.generatePredictionNetworkTrainingDataFromStreamlines(streamlines_filtered, dwi_B0normalized, noX=noX,noY=noY,noZ=noZ,coordinateScaling=coordinateScaling,distToNeighbours=1, noCrossings = noCrossings)\n",
    "runtime = time.time() - start_time\n",
    "print('Runtime ' + str(runtime) + ' s ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(pTrainData_fibrePrediction,\"w\") as f:\n",
    "    f.create_dataset('train_DWI',data=train_DWI)\n",
    "    f.create_dataset('train_curPosition',data=train_curPosition)   \n",
    "    f.create_dataset('train_LikelyFibreDirections',data=train_LikelyFibreDirections)   \n",
    "    f.create_dataset('train_NextFibreDirection',data=train_NextFibreDirection)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "noGPUs = 3\n",
    "batch_size = 2**8\n",
    "batch_size -= batch_size % noGPUs # make batch size divisible by no. of GPUs\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File(pTrainData_fibrePrediction, \"r\")\n",
    "train_DWI = np.array(f[\"train_DWI\"].value)\n",
    "train_lastDirection = np.array(f[\"train_curPosition\"].value)\n",
    "train_LikelyFibreDirections = np.array(f[\"train_LikelyFibreDirections\"].value)\n",
    "train_NextFibreDirection = np.array(f[\"train_NextFibreDirection\"].value)\n",
    "f.close()\n",
    "#train_lastDirection = np.expand_dims(train_lastDirection, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond = train_NextFibreDirection == [0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nico/Code/deepFibreTracking/src/nn_helper.py:27: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  vecs = np.nan_to_num(vecs / vecNorms[:,None])\n",
      "/home/nico/Code/deepFibreTracking/src/nn_helper.py:27: RuntimeWarning: invalid value encountered in true_divide\n",
      "  vecs = np.nan_to_num(vecs / vecNorms[:,None])\n"
     ]
    }
   ],
   "source": [
    "#train_LikelyFibreDirections = (train_LikelyFibreDirections + 1) / 2\n",
    "#train_lastDirection = (train_lastDirection + 1) / 2\n",
    "#train_DWI = nn_helper.normalizeDWI(train_DWI)\n",
    "train_lastDirection_unit = nn_helper.normalizeStreamlineOrientation(train_lastDirection)\n",
    "train_NextFibreDirection_unit = nn_helper.normalizeStreamlineOrientation(train_NextFibreDirection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSD Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "\n",
    "import importlib\n",
    "importlib.reload(nn_helper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "msd_simple = nn_helper.get_msd_simplified_trackerNetwork(activation_function = LeakyReLU(), inputShapeDWI=(noX, noY, noZ, 270),depth = 3, noGPUs=noGPUs)\n",
    "msd_simple.fit([train_DWI], [train_NextFibreDirection_unit], batch_size=batch_size, epochs=epochs, verbose=1,validation_split=0.2, callbacks=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "msd_tracker = nn_helper.get_msd_trackerNetwork(activation_function = LeakyReLU(), inputShape1=(noX, noY, noZ, 288),inputShape2=(1,3),depth = 3, noCrossings = noCrossings, noGPUs=noGPUs)\n",
    "msd_tracker.fit([train_DWI,train_lastDirection_unit], [train_LikelyFibreDirections,train_NextFibreDirection_unit], batch_size=batch_size, epochs=epochs, verbose=1,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.nn_helper as nn_helper\n",
    "importlib.reload(nn_helper)\n",
    "unet_tracker = nn_helper.get_3Dunet_advancedTracker(activation_function = LeakyReLU(), inputShapeDWI=(noX, noY, noZ, 288),inputShapeStreamline=(1,3),depth = 3, noGPUs=noGPUs)\n",
    "unet_tracker.fit([train_DWI, train_lastDirection_unit], [train_NextFibreDirection_unit], batch_size=batch_size, epochs=epochs, verbose=1,validation_split=0.2, callbacks=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "no batch normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.nn_helper as nn_helper\n",
    "importlib.reload(nn_helper)\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger, ReduceLROnPlateau, EarlyStopping\n",
    "pModel = \"tractography_model_{epoch:02d}-{val_loss:.6f}.h5\"\n",
    "unet_tracker = nn_helper.get_3Dunet_simpleTracker(activation_function = LeakyReLU(), inputShapeDWI=(noX, noY, noZ, 270),depth = 3, noGPUs=noGPUs)\n",
    "csv_logger = CSVLogger(\"tractography_log.csv\")\n",
    "checkpoint = ModelCheckpoint(pModel, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list=[checkpoint, csv_logger]\n",
    "unet_tracker.fit([train_DWI], [train_NextFibreDirection_unit], batch_size=batch_size, epochs=100, verbose=1, validation_split=0.2, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def relu_advanced(x):\n",
    "    return K.relu(x, max_value=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 57936 samples, validate on 14484 samples\n",
      "Epoch 1/100\n",
      "57936/57936 [==============================] - 60s 1ms/step - loss: -0.8640 - val_loss: -0.8916\n",
      "Epoch 2/100\n",
      "57936/57936 [==============================] - 56s 972us/step - loss: -0.8938 - val_loss: -0.9263\n",
      "Epoch 3/100\n",
      "57936/57936 [==============================] - 57s 977us/step - loss: -0.9129 - val_loss: -0.9331\n",
      "Epoch 4/100\n",
      "57936/57936 [==============================] - 57s 991us/step - loss: -0.9228 - val_loss: -0.9342\n",
      "Epoch 5/100\n",
      "57936/57936 [==============================] - 57s 981us/step - loss: -0.9284 - val_loss: -0.9367\n",
      "Epoch 6/100\n",
      "57936/57936 [==============================] - 57s 986us/step - loss: -0.9334 - val_loss: -0.9428\n",
      "Epoch 7/100\n",
      "57936/57936 [==============================] - 57s 992us/step - loss: -0.9371 - val_loss: -0.9474\n",
      "Epoch 8/100\n",
      "57936/57936 [==============================] - 57s 981us/step - loss: -0.9405 - val_loss: -0.9504\n",
      "Epoch 9/100\n",
      "57936/57936 [==============================] - 58s 994us/step - loss: -0.9432 - val_loss: -0.9517\n",
      "Epoch 10/100\n",
      "57936/57936 [==============================] - 57s 991us/step - loss: -0.9457 - val_loss: -0.9476\n",
      "Epoch 11/100\n",
      "57936/57936 [==============================] - 57s 977us/step - loss: -0.9475 - val_loss: -0.9510\n",
      "Epoch 12/100\n",
      "57936/57936 [==============================] - 56s 975us/step - loss: -0.9496 - val_loss: -0.9518\n",
      "Epoch 13/100\n",
      "57936/57936 [==============================] - 57s 984us/step - loss: -0.9509 - val_loss: -0.9551\n",
      "Epoch 14/100\n",
      "57936/57936 [==============================] - 57s 984us/step - loss: -0.9519 - val_loss: -0.9581\n",
      "Epoch 15/100\n",
      "57936/57936 [==============================] - 57s 986us/step - loss: -0.9527 - val_loss: -0.9520\n",
      "Epoch 16/100\n",
      "57936/57936 [==============================] - 57s 982us/step - loss: -0.9539 - val_loss: -0.9527\n",
      "Epoch 17/100\n",
      "57936/57936 [==============================] - 57s 987us/step - loss: -0.9545 - val_loss: -0.9573\n",
      "Epoch 18/100\n",
      "57936/57936 [==============================] - 57s 986us/step - loss: -0.9555 - val_loss: -0.9553\n",
      "Epoch 19/100\n",
      "57936/57936 [==============================] - 56s 974us/step - loss: -0.9561 - val_loss: -0.9606\n",
      "Epoch 20/100\n",
      "57936/57936 [==============================] - 57s 978us/step - loss: -0.9566 - val_loss: -0.9583\n",
      "Epoch 21/100\n",
      "57936/57936 [==============================] - 56s 975us/step - loss: -0.9573 - val_loss: -0.9588\n",
      "Epoch 22/100\n",
      "57936/57936 [==============================] - 56s 975us/step - loss: -0.9578 - val_loss: -0.9610\n",
      "Epoch 23/100\n",
      "57936/57936 [==============================] - 57s 975us/step - loss: -0.9586 - val_loss: -0.9603\n",
      "Epoch 24/100\n",
      "57936/57936 [==============================] - 57s 981us/step - loss: -0.9594 - val_loss: -0.9601\n",
      "Epoch 25/100\n",
      "57936/57936 [==============================] - 57s 983us/step - loss: -0.9588 - val_loss: -0.9612\n",
      "Epoch 26/100\n",
      "57936/57936 [==============================] - 57s 978us/step - loss: -0.9601 - val_loss: -0.9602\n",
      "Epoch 27/100\n",
      "57936/57936 [==============================] - 57s 978us/step - loss: -0.9599 - val_loss: -0.9636\n",
      "Epoch 28/100\n",
      "57936/57936 [==============================] - 57s 982us/step - loss: -0.9602 - val_loss: -0.9601\n",
      "Epoch 29/100\n",
      "57936/57936 [==============================] - 57s 984us/step - loss: -0.9611 - val_loss: -0.9656\n",
      "Epoch 30/100\n",
      "57936/57936 [==============================] - 56s 972us/step - loss: -0.9618 - val_loss: -0.9574\n",
      "Epoch 31/100\n",
      "57936/57936 [==============================] - 57s 980us/step - loss: -0.9614 - val_loss: -0.9641\n",
      "Epoch 32/100\n",
      "57936/57936 [==============================] - 57s 976us/step - loss: -0.9619 - val_loss: -0.9636\n",
      "Epoch 33/100\n",
      "57936/57936 [==============================] - 57s 981us/step - loss: -0.9596 - val_loss: -0.9658\n",
      "Epoch 34/100\n",
      "57936/57936 [==============================] - 57s 984us/step - loss: -0.9597 - val_loss: -0.9632\n",
      "Epoch 35/100\n",
      "57936/57936 [==============================] - 57s 984us/step - loss: -0.9603 - val_loss: -0.9661\n",
      "Epoch 36/100\n",
      "57936/57936 [==============================] - 57s 979us/step - loss: -0.9604 - val_loss: -0.9663\n",
      "Epoch 37/100\n",
      "57936/57936 [==============================] - 57s 991us/step - loss: -0.9605 - val_loss: -0.9632\n",
      "Epoch 38/100\n",
      "57936/57936 [==============================] - 57s 982us/step - loss: -0.9607 - val_loss: -0.9624\n",
      "Epoch 39/100\n",
      "57936/57936 [==============================] - 57s 980us/step - loss: -0.9612 - val_loss: -0.9651\n",
      "Epoch 40/100\n",
      "57936/57936 [==============================] - 57s 976us/step - loss: -0.9614 - val_loss: -0.9635\n",
      "Epoch 41/100\n",
      "57936/57936 [==============================] - 57s 980us/step - loss: -0.9612 - val_loss: -0.9647\n",
      "Epoch 42/100\n",
      "57936/57936 [==============================] - 58s 997us/step - loss: -0.9618 - val_loss: -0.9676\n",
      "Epoch 43/100\n",
      "57936/57936 [==============================] - 57s 979us/step - loss: -0.9607 - val_loss: -0.9631\n",
      "Epoch 44/100\n",
      "57936/57936 [==============================] - 57s 977us/step - loss: -0.9622 - val_loss: -0.9642\n",
      "Epoch 45/100\n",
      "57936/57936 [==============================] - 57s 986us/step - loss: -0.9617 - val_loss: -0.9660\n",
      "Epoch 46/100\n",
      "57936/57936 [==============================] - 57s 979us/step - loss: -0.9620 - val_loss: -0.9580\n",
      "Epoch 47/100\n",
      "57936/57936 [==============================] - 56s 970us/step - loss: -0.9620 - val_loss: -0.9659\n",
      "Epoch 48/100\n",
      "57936/57936 [==============================] - 56s 974us/step - loss: -0.9594 - val_loss: -0.9654\n",
      "Epoch 49/100\n",
      "57936/57936 [==============================] - 57s 977us/step - loss: -0.9591 - val_loss: -0.9671\n",
      "Epoch 50/100\n",
      "57936/57936 [==============================] - 56s 974us/step - loss: -0.9587 - val_loss: -0.9670\n",
      "Epoch 51/100\n",
      "57936/57936 [==============================] - 57s 978us/step - loss: -0.9593 - val_loss: -0.9626\n",
      "Epoch 52/100\n",
      "57936/57936 [==============================] - 57s 986us/step - loss: -0.9592 - val_loss: -0.9654\n",
      "Epoch 53/100\n",
      "57936/57936 [==============================] - 56s 970us/step - loss: -0.9591 - val_loss: -0.9650\n",
      "Epoch 54/100\n",
      "57936/57936 [==============================] - 56s 966us/step - loss: -0.9596 - val_loss: -0.9647\n",
      "Epoch 55/100\n",
      "57936/57936 [==============================] - 57s 979us/step - loss: -0.9595 - val_loss: -0.9670\n",
      "Epoch 56/100\n",
      "57936/57936 [==============================] - 57s 979us/step - loss: -0.9597 - val_loss: -0.9655\n",
      "Epoch 57/100\n",
      "57936/57936 [==============================] - 56s 973us/step - loss: -0.9598 - val_loss: -0.9661\n",
      "Epoch 58/100\n",
      "57936/57936 [==============================] - 57s 978us/step - loss: -0.9600 - val_loss: -0.9648\n",
      "Epoch 59/100\n",
      "57936/57936 [==============================] - 57s 983us/step - loss: -0.9600 - val_loss: -0.9665\n",
      "Epoch 60/100\n",
      "57936/57936 [==============================] - 56s 971us/step - loss: -0.9601 - val_loss: -0.9660\n",
      "Epoch 61/100\n",
      "57936/57936 [==============================] - 56s 974us/step - loss: -0.9602 - val_loss: -0.9667\n",
      "Epoch 62/100\n",
      "57936/57936 [==============================] - 57s 981us/step - loss: -0.9606 - val_loss: -0.9631\n",
      "Epoch 63/100\n",
      "57936/57936 [==============================] - 57s 986us/step - loss: -0.9600 - val_loss: -0.9647\n",
      "Epoch 64/100\n",
      "57936/57936 [==============================] - 57s 978us/step - loss: -0.9604 - val_loss: -0.9646\n",
      "Epoch 65/100\n",
      "57936/57936 [==============================] - 56s 973us/step - loss: -0.9603 - val_loss: -0.9664\n",
      "Epoch 66/100\n",
      "57936/57936 [==============================] - 57s 976us/step - loss: -0.9608 - val_loss: -0.9636\n",
      "Epoch 67/100\n",
      "57936/57936 [==============================] - 56s 974us/step - loss: -0.9607 - val_loss: -0.9662\n",
      "Epoch 68/100\n",
      "57936/57936 [==============================] - 57s 986us/step - loss: -0.9606 - val_loss: -0.9655\n",
      "Epoch 69/100\n",
      "57936/57936 [==============================] - 56s 974us/step - loss: -0.9599 - val_loss: -0.9602\n",
      "Epoch 70/100\n",
      "57936/57936 [==============================] - 57s 988us/step - loss: -0.9567 - val_loss: -0.9648\n",
      "Epoch 71/100\n",
      "57936/57936 [==============================] - 56s 975us/step - loss: -0.9576 - val_loss: -0.9648\n",
      "Epoch 72/100\n",
      "57936/57936 [==============================] - 56s 974us/step - loss: -0.9578 - val_loss: -0.9626\n",
      "Epoch 73/100\n",
      "57936/57936 [==============================] - 56s 969us/step - loss: -0.9576 - val_loss: -0.9623\n",
      "Epoch 74/100\n",
      "57936/57936 [==============================] - 57s 978us/step - loss: -0.9576 - val_loss: -0.9622\n",
      "Epoch 75/100\n",
      "57936/57936 [==============================] - 56s 964us/step - loss: -0.9574 - val_loss: -0.9630\n",
      "Epoch 76/100\n",
      "57936/57936 [==============================] - 55s 956us/step - loss: -0.9582 - val_loss: -0.9658\n",
      "Epoch 77/100\n",
      "57936/57936 [==============================] - 56s 971us/step - loss: -0.9579 - val_loss: -0.9638\n",
      "Epoch 78/100\n",
      "57936/57936 [==============================] - 56s 971us/step - loss: -0.9578 - val_loss: -0.9658\n",
      "Epoch 79/100\n",
      "57936/57936 [==============================] - 56s 963us/step - loss: -0.9585 - val_loss: -0.9644\n",
      "Epoch 80/100\n",
      "57936/57936 [==============================] - 55s 957us/step - loss: -0.9582 - val_loss: -0.9657\n",
      "Epoch 81/100\n",
      "57936/57936 [==============================] - 56s 971us/step - loss: -0.9581 - val_loss: -0.9657\n",
      "Epoch 82/100\n",
      "57936/57936 [==============================] - 56s 968us/step - loss: -0.9570 - val_loss: -0.9639\n",
      "Epoch 83/100\n",
      "57936/57936 [==============================] - 56s 967us/step - loss: -0.9585 - val_loss: -0.9660\n",
      "Epoch 84/100\n",
      "57936/57936 [==============================] - 57s 978us/step - loss: -0.9585 - val_loss: -0.9643\n",
      "Epoch 85/100\n",
      "57936/57936 [==============================] - 57s 975us/step - loss: -0.9584 - val_loss: -0.9658\n",
      "Epoch 86/100\n",
      "57936/57936 [==============================] - 55s 950us/step - loss: -0.9590 - val_loss: -0.9627\n",
      "Epoch 87/100\n",
      "57936/57936 [==============================] - 56s 971us/step - loss: -0.9584 - val_loss: -0.9648\n",
      "Epoch 88/100\n",
      "57936/57936 [==============================] - 56s 968us/step - loss: -0.9591 - val_loss: -0.9666\n",
      "Epoch 89/100\n",
      "57936/57936 [==============================] - 56s 973us/step - loss: -0.9592 - val_loss: -0.9667\n",
      "Epoch 90/100\n",
      "57936/57936 [==============================] - 56s 968us/step - loss: -0.9592 - val_loss: -0.9558\n",
      "Epoch 91/100\n",
      "57936/57936 [==============================] - 56s 972us/step - loss: -0.9587 - val_loss: -0.9635\n",
      "Epoch 92/100\n",
      "57936/57936 [==============================] - 56s 969us/step - loss: -0.9594 - val_loss: -0.9664\n",
      "Epoch 93/100\n",
      "57936/57936 [==============================] - 56s 970us/step - loss: -0.9595 - val_loss: -0.9669\n",
      "Epoch 94/100\n",
      "57936/57936 [==============================] - 57s 975us/step - loss: -0.9592 - val_loss: -0.9666\n",
      "Epoch 95/100\n",
      "57936/57936 [==============================] - 56s 968us/step - loss: -0.9593 - val_loss: -0.9665\n",
      "Epoch 96/100\n",
      "57936/57936 [==============================] - 55s 950us/step - loss: -0.9597 - val_loss: -0.9528\n",
      "Epoch 97/100\n",
      "57936/57936 [==============================] - 56s 960us/step - loss: -0.9590 - val_loss: -0.9656\n",
      "Epoch 98/100\n",
      "57936/57936 [==============================] - 56s 973us/step - loss: -0.9602 - val_loss: -0.9684\n",
      "Epoch 99/100\n",
      "57936/57936 [==============================] - 56s 964us/step - loss: -0.9595 - val_loss: -0.9659\n",
      "Epoch 100/100\n",
      "57936/57936 [==============================] - 55s 948us/step - loss: -0.9597 - val_loss: -0.9651\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6cd8ff35c0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "import importlib\n",
    "import src.nn_helper as nn_helper\n",
    "importlib.reload(nn_helper)\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger, ReduceLROnPlateau, EarlyStopping\n",
    "pModel = \"tractography_model_{epoch:02d}-{val_loss:.6f}.h5\"\n",
    "#mlp_tracker = nn_helper.get_mlp_simpleTracker(activation_function = LeakyReLU(), inputShapeDWI=(noX, noY, noZ, 270),depth = 3, noGPUs=noGPUs)\n",
    "mlp_tracker = nn_helper.get_mlp_simpleTracker(features = 512, lr = 1e-4, activation_function = keras.layers.core.Activation(relu_advanced), inputShapeDWI=(noX, noY, noZ, 270),depth = 3, noGPUs=noGPUs)\n",
    "mlp_tracker.fit([train_DWI], [train_NextFibreDirection_unit], batch_size=batch_size, epochs=100, verbose=1, validation_split=0.2, callbacks=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.prod((8,8,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.tracking as tracking\n",
    "importlib.reload(tracking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(train_DWI[0,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(train_DWI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(train_DWI[0,])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP/Simple Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime 72.57033061981201 s \n"
     ]
    }
   ],
   "source": [
    "import src.tracking as tracking\n",
    "importlib.reload(tracking)\n",
    "start_time = time.time()\n",
    "streamlines_mlp_simple = tracking.applySimpleTrackerNetwork(seeds=ccseeds[0:50],data=dwi_B0normalized, model=mlp_tracker, noX=noX, noY=noY, noZ=noZ, dw = 270, stepWidth = 0.1, coordinateScaling = coordinateScaling)\n",
    "runtime = time.time() - start_time\n",
    "print('Runtime ' + str(runtime) + ' s ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('streamlines_mlp_simple.npy', streamlines_mlp_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.tracking as tracking\n",
    "importlib.reload(tracking)\n",
    "start_time = time.time()\n",
    "streamlines_mlp_simple = tracking.applySimpleTrackerNetwork(seeds=ccseeds,data=dwi_B0normalized, model=mlp_tracker, noX=noX, noY=noY, noZ=noZ, dw = 270, stepWidth = 0.1, coordinateScaling = coordinateScaling)\n",
    "runtime = time.time() - start_time\n",
    "print('Runtime ' + str(runtime) + ' s ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streamlines_mlp_simple[0,5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streamlines_mlp_simple[0,6,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nico/anaconda3/lib/python3.6/site-packages/vtk/util/numpy_support.py:137: FutureWarning: Conversion of the second argument of issubdtype from `complex` to `np.complexfloating` is deprecated. In future, it will be treated as `np.complex128 == np.dtype(complex).type`.\n",
      "  assert not numpy.issubdtype(z.dtype, complex), \\\n"
     ]
    }
   ],
   "source": [
    "import src.dwi_tools as dwi_tools\n",
    "importlib.reload(dwi_tools)\n",
    "dwi_tools.visStreamlines(streamlines_mlp_simple,t1, vol_slice_idx = 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSD/Simple Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.tracking as tracking\n",
    "importlib.reload(tracking)\n",
    "start_time = time.time()\n",
    "streamlines_msd_simple = tracking.applySimpleTrackerNetwork(seeds=[ccseeds[0:100]],data=dwi_B0normalized, model=msd_simple, noX=noX, noY=noY, noZ=noZ, dw = 270, stepWidth = 0.1, coordinateScaling = coordinateScaling)\n",
    "runtime = time.time() - start_time\n",
    "print('Runtime ' + str(runtime) + ' s ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streamlines_msd_simple[0,5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streamlines_msd_simple[0,6,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.dwi_tools as dwi_tools\n",
    "importlib.reload(dwi_tools)\n",
    "dwi_tools.visStreamlines(streamlines_msd_simple,t1, vol_slice_idx = 73)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSD/Advanced Tracking Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "streamlines_msd_adv = tracking.applyTrackerNetwork(seeds=ccseeds,data=dwi, model=msd, noX=noX, noY=noY, noZ=noZ, coordinateScaling=coordinateScaling)\n",
    "runtime = time.time() - start_time\n",
    "print('Runtime ' + str(runtime) + ' s ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dwi_tools.visStreamlines(streamlines_msd_adv,t1, vol_slice_idx = 73)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UNET/Advanced Tracking Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "streamlines = tracking.applyTrackerNetwork(seeds=ccseeds,data=dwi, model=unet_tracker, noX=noX, noY=noY, noZ=noZ, coordinateScaling=coordinateScaling)\n",
    "runtime = time.time() - start_time\n",
    "print('Runtime ' + str(runtime) + ' s ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dwi_tools.visStreamlines(streamlines,t1, vol_slice_idx = 73)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
