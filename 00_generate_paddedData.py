import os
import sys
import h5py
import numpy as np 

import torch
from torch.autograd import Variable
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import argparse

from src.util import info, progress

def custom_padding(train_DWI, lengths):
    """Applies another type of padding to the given tensor, it just keeps repeating the last direction till the end of the array. Returns the modified train_DWI.

    Arguments:
    train_DWI: the tensor for padding
    lengths: the lengths of each streamline
    """
    for i in range(train_DWI.shape[1]):
         
        train_DWI[lengths[i]:200,i] = train_DWI[lengths[i]-1,i]
                
        progress(100 * (i)/ float(train_DWI.shape[1]), text="Calculating....")
    return train_DWI        

def normalizeAndFix(nextDirection):
    """Normalizes the given nextDirection tensor and replaces the null vektor with the inverse last direction. Returns the fixed vector.

    Arguments:
    nextDirection: the tensor to be fixed
    """
    # normalize data and set last element to negative direction
    nextDirection = nextDirection / torch.norm(nextDirection,dim=1).unsqueeze(1) # normalize next direction
    nextDirection[-1,:] =  -1*nextDirection[-2,:] #overwrite NaN at 0 0 0 element with reverse direction
    return nextDirection    
def reverseLine(curr_DWI, curr_nextDirection):
    """Calculates the inverse streamline for given streamline and returns the streamline as tuple (dwi, nextDirection).

    Arguments:
    curr_DWI: the DWI information
    curr_nextDirection: the nextDireciton information
    """
    # calculates reverse Fiber for Training
    # Backwards motion
    curr_nextDirection_back = (torch.cat((curr_nextDirection[-1:], curr_nextDirection[:-1])) * -1).flip([0]) # backward tracking - circular shift by one, multiply with  -1 and flip on 0 dimension
    curr_DWI_back = curr_DWI.flip([0]) # just flip for input data
    curr_nextDirection_back[-1,:] = -1*curr_nextDirection[-2,:]
    return curr_DWI_back, curr_nextDirection_back
def prepareData():
    """prepares the data from linear format as given in 00_generateTrainingData.py to multidimensional format with single streamlines for training 
    and saves them to cache/data_ijk.pt. Normalizing and padding is applied to the given data.    
    """
    parser = argparse.ArgumentParser(description='Deep Learning Tractography -- Data Padding')
    parser.add_argument('-mal', dest='maxLength', default=201, type=int, help='maximum length of single streamline. default: 201')
    parser.add_argument('-input', dest='inputfile', default='./train/HCP100307_b1000_res100_sw1.0_3x3x3_ut0_rotatedN51_epN0_spc1.00.h5', help='Input file generated by 00_generateTrainingData.py')
    parser.add_argument('--useCustomPadding', dest="custom_pad", action="store_true", help='Use custom padding instead of zero padding')
    parser.set_defaults(custom_pad=False)
    args = parser.parse_args()
    info("Start reading inputfile...")
    # INPUT
    pData = args.inputfile
    f = h5py.File(pData, "r")
    data_DWI = np.array(f["train_DWI"][()])
    data_DWI = torch.from_numpy(data_DWI).float()
    feature_size = data_DWI.shape[-1] * data_DWI.shape[-2] * data_DWI.shape[-3] * data_DWI.shape[-4]
    # [871936, 1, 1, 1, 100]
    data_nextDirection = np.array(f["train_NextFibreDirection"][()])
    data_nextDirection = torch.from_numpy(data_nextDirection).float()
    # [871936, 3]
    streamlineIndices = np.array(f["streamlineIndices"][()])
    streamlineIndices = torch.from_numpy(streamlineIndices).float()
    # [10000, 3]
    f.close()
    
    noStreamlines = len(streamlineIndices)
    info("Succesfully read {} streamlines".format(noStreamlines))
    oi = 0
    MAX_LENGTH = args.maxLength
    train_DWI = torch.zeros(noStreamlines,MAX_LENGTH,feature_size, dtype=torch.float32) # batch size (10000*2 - forward and backward), max timestep length, feature size 
    train_padded_lengths = torch.IntTensor(noStreamlines)  # variable timestep length
    train_nextDirection = torch.zeros(noStreamlines,MAX_LENGTH,3, dtype=torch.float32) # batch size, max timestep length, feature size
        
    info("Initalized Tensors")
    for _i in range(1,noStreamlines):
        i = streamlineIndices[_i][0].int().item() #end indice
        # oi = begin indice
        # retain data from file
        curr_DWI = data_DWI[oi:i,:]
        curr_DWI.resize_(i-oi,feature_size)
        
        curr_nextDirection = data_nextDirection[oi:i,:]
        curr_nextDirection = normalizeAndFix(curr_nextDirection)
        # appending data to output and fill with zeros forwards
        train_DWI[_i-1,:i-oi,:] = curr_DWI
        train_nextDirection[_i-1,:i-oi,:] = curr_nextDirection
        train_padded_lengths[_i-1] = i-oi  
        oi  = i # old index = index
        
        #just optical representation of progress
        progress(100 * (_i / float(noStreamlines)), text="Calculating....")
    print()

    # last element

    i = len(data_DWI) 
    # retain data from file
    curr_DWI =  data_DWI[oi:i,:]
    curr_DWI.resize_(i-oi,feature_size)
    curr_nextDirection = data_nextDirection[oi:i,:]
    curr_nextDirection = normalizeAndFix(curr_nextDirection)
    
    # appending data to output and fill with zeros forwards and backwards
    train_DWI[noStreamlines-1,:i-oi,:] = curr_DWI
    train_nextDirection[noStreamlines-1,:i-oi,:] = curr_nextDirection
    train_padded_lengths[noStreamlines-1] = i-oi 
    if args.custom_pad:
        train_DWI = custom_pad(train_DWI, train_padded_lengths)

    info("Saving Data")
    torch.save((train_DWI[:,:,:],train_nextDirection,train_padded_lengths),'cache/data_ijk.pt')
    info("Saved Data")

if __name__ == "__main__":
    prepareData()
